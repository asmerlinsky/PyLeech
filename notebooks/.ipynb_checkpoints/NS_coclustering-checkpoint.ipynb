{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agus\\Dropbox\\Doctorado\\NeuroData\\PyLeech\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agus\\Dropbox\\Doctorado\\NeuroData\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyLeech.Utils.CrawlingDatabaseUtils as CDU\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PyLeech.Utils.NLDUtils as NLD\n",
    "import scipy.signal as spsig\n",
    "import os.path\n",
    "import winsound\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import PyLeech.Utils.AbfExtension as abfe\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RegistrosDP_PP\\\\18n05010.pklspikes', 'RegistrosDP_PP\\\\2018_10_11_0002.pklspikes', 'RegistrosDP_PP\\\\2018_12_03_0005.pklspikes', 'RegistrosDP_PP\\\\2018_12_04_0003_0004_0005_0006b.pklspikes', 'RegistrosDP_PP\\\\2018_12_06_0005.pklspikes', 'RegistrosDP_PP\\\\2018_12_13_0015.pklspikes', 'RegistrosDP_PP\\\\NS_DP_PP_0.pklspikes', 'RegistrosDP_PP\\\\NS_T_DP_PP_0_cut.pklspikes', 'RegistrosDP_PP\\\\NS_T_DP_PP_1.pklspikes', 'RegistrosDP_PP\\\\2014_09_25_0008.pklspikes', 'RegistrosDP_PP\\\\2019_01_28_0001.pklspikes', 'RegistrosDP_PP\\\\2018_11_06_0004.pklspikes', 'RegistrosDP_PP\\\\2018_12_03_0000_0001.pklspikes', 'RegistrosDP_PP\\\\14217000.pklspikes', 'RegistrosDP_PP\\\\2017_12_08_0002.pklspikes', 'RegistrosDP_PP\\\\cont10.pklspikes', 'RegistrosDP_PP\\\\2018_12_13_0001.pklspikes', 'RegistrosDP_PP\\\\2019_07_22_0002.pklspikes', 'RegistrosDP_PP\\\\2019_07_22_0009.pklspikes', 'RegistrosDP_PP\\\\2019_07_22_0011.pklspikes', 'RegistrosDP_PP\\\\2019_07_23_0004.pklspikes', 'RegistrosDP_PP\\\\2019_07_23_0008.pklspikes', 'RegistrosDP_PP\\\\2019_07_23_0014.pklspikes', 'RegistrosDP_PP\\\\2019_08_28_0005.pklspikes', 'RegistrosDP_PP\\\\2019_08_30_0003.pklspikes', 'RegistrosDP_PP\\\\2019_08_30_0006.pklspikes']\n"
     ]
    }
   ],
   "source": [
    "cdd = CDU.loadDataDict()\n",
    "file_list = list(cdd)\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RegistrosDP_PP\\\\2018_12_03_0005.pklspikes', 'RegistrosDP_PP\\\\2019_07_22_0002.pklspikes', 'RegistrosDP_PP\\\\2019_07_22_0009.pklspikes', 'RegistrosDP_PP\\\\2019_07_22_0011.pklspikes', 'RegistrosDP_PP\\\\2019_07_23_0008.pklspikes', 'RegistrosDP_PP\\\\2019_08_30_0003.pklspikes', 'RegistrosDP_PP\\\\2019_08_30_0006.pklspikes']\n"
     ]
    }
   ],
   "source": [
    "cdd = CDU.loadDataDict()\n",
    "file_list = list(cdd)\n",
    "binning_dt = .1\n",
    "spike_kernel_sigma = 3\n",
    "\n",
    "trace_list = []\n",
    "emb_list = []\n",
    "ran_files = []\n",
    "run_dict = {}\n",
    "file_sel = [\n",
    "    '2019_07_22_0009', \n",
    "    '2019_07_22_0002',\n",
    "    '2019_07_22_0011',\n",
    "    '2019_08_30_0003',\n",
    "    '2019_08_30_0006',\n",
    "    '2018_12_03_0005',\n",
    "    '2019_07_23_0008'\n",
    "]\n",
    "sublist = [fn for fn in file_list if any([fs in fn for fs in file_sel])]\n",
    "print(sublist)\n",
    "cycle_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "every_single_cycle = []\n",
    "every_double_cycle = []\n",
    "cycle_map = []\n",
    "double_cycle_map = []\n",
    "i = 0\n",
    "for fn in sublist:\n",
    "    ns_channel = [key for key, items in cdd[fn]['channels'].items() if 'NS' == items][0]\n",
    "    fn = abfe.getAbFileListFromBasename(fn)[0]\n",
    "    arr_dict, time_vector , fs = abfe.getArraysFromAbfFiles(fn, [ns_channel])\n",
    "    NS_kernel = NLD.generateGaussianKernel(sigma=spike_kernel_sigma, time_range=20, dt_step=1 / fs)\n",
    "    bl_kernel = NLD.generateGaussianKernel(sigma=45, time_range=10*60, dt_step=1 / fs)\n",
    "    data = arr_dict[ns_channel] - np.mean(arr_dict[ns_channel])\n",
    "    data[(data<-20) | (data>20)] = 0\n",
    "    \n",
    "    bl = spsig.fftconvolve(data, bl_kernel, mode='same')[::int(binning_dt * fs)]\n",
    "\n",
    "    trace = spsig.fftconvolve(data, NS_kernel, mode='same')[::int(binning_dt * fs)]\n",
    "    \n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.plot(trace)\n",
    "#     ax.plot(bl)\n",
    "#     fig.suptitle(fn)\n",
    "    \n",
    "    if '2019_07_22_0009' in fn:\n",
    "        trace = (trace-bl)[1600:9200]### solo porque estoy correndo el 2019 07 22 0009\n",
    "        peak_height = 2.4\n",
    "    elif '2019_07_22_0002' in fn:\n",
    "        trace = (trace-bl)[900:10000]### solo porque estoy correndo el 2019 07 22 0002\n",
    "        peak_height = 2.4\n",
    "    elif '2019_07_22_0011' in fn:\n",
    "        trace = (trace-bl)[3000:11000]### solo porque estoy correndo el 2019 07 22 0011\n",
    "        peak_height = 1\n",
    "    elif '2019_08_30_0003' in fn:\n",
    "        trace = (trace-bl)[2500:9600]### solo porque estoy correndo el 2019 07 22 0011\n",
    "        peak_height = 1\n",
    "    elif '2019_08_30_0006' in fn:\n",
    "        trace = (trace-bl)[1800:6800]\n",
    "        peak_height = 3.3\n",
    "    elif '2019_07_23_0008' in fn:\n",
    "        trace = (trace-bl)[3700:8400]\n",
    "        peak_height = 1.5\n",
    "    elif '2018_12_03_0005' in fn:\n",
    "        trace = (trace-bl)[2200:7800]\n",
    "        peak_height = 1.5\n",
    "\n",
    " \n",
    "    cycles = NLD.getCycles(trace, fs=binning_dt, peak_height=peak_height)\n",
    "    Ncycles = NLD.getNCycles(trace, fs=binning_dt, peak_height=peak_height, N=2)\n",
    "\n",
    "    \n",
    "#     resampled_trace = NLD.resampleByCycles(trace, fs=binning_dt, peak_height=peak_height)\n",
    "#     kernel = NLD.generateGaussianKernel(sigma=1.5, time_range=2, dt_step=binning_dt)\n",
    "#     smoothed_resampled_trace = spsig.fftconvolve(resampled_trace, kernel, mode='same')\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(trace)\n",
    "#     fig1, ax1 = plt.subplots()\n",
    "#     ax1.plot(resampled_trace)\n",
    "#     fig1.suptitle(fn)\n",
    "#     ax1.plot(smoothed_resampled_trace)\n",
    "#     fig, ax = NLD.plotCycles(trace, fs=binning_dt, peak_height=peak_height)\n",
    "#     fig.suptitle(fn)\n",
    "#     fig, ax = NLD.plotCycles(trace, fs=binning_dt, peak_height=peak_height, N=2)\n",
    "#     fig.suptitle(fn)\n",
    "    \n",
    "    cycle_dict[fn] = {'1m': cycles, '2m':Ncycles}\n",
    "    \n",
    "#     for x, y in NLD.getSimilarCycles(cycles, 15):\n",
    "#         fig, ax = plt.subplots()\n",
    "#         ax.plot(cycles[x])\n",
    "#         ax.plot(cycles[y])\n",
    "#         fig.suptitle(fn + ' single')\n",
    "#         ax.set_title(str(x) + ' ' + str(y))\n",
    "    \n",
    "#     for x, y in NLD.getSimilarCycles(Ncycles, 10):\n",
    "#         fig, ax = plt.subplots()\n",
    "#         ax.plot(Ncycles[x])\n",
    "#         ax.plot(Ncycles[y])\n",
    "#         fig.suptitle(fn + ' double')\n",
    "#         ax.set_title(str(x) + ' ' + str(y))\n",
    "        \n",
    "    every_single_cycle.extend(cycles)\n",
    "    every_double_cycle.extend(Ncycles)\n",
    "    for j in range(i, i+len(cycles)):\n",
    "        cycle_map.append(fn)\n",
    "    for j in range(i, i+len(Ncycles)):\n",
    "        double_cycle_map.append(fn)\n",
    "    i += len(cycles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for cycle in every_single_cycle:\n",
    "    if cycle.shape[0]>max_len:\n",
    "        max_len = cycle.shape[0]\n",
    "\n",
    "for i in range(len(every_single_cycle)):\n",
    "    every_single_cycle[i] = spsig.resample(every_single_cycle[i], num=max_len)\n",
    "\n",
    "max_len = 0\n",
    "for cycle in every_double_cycle:\n",
    "    if cycle.shape[0]>max_len:\n",
    "        max_len = cycle.shape[0]\n",
    "\n",
    "for i in range(len(every_double_cycle)):\n",
    "    every_double_cycle[i] = spsig.resample(every_double_cycle[i], num=max_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Entonces, para un máximo (el '2019_07_22_0009')\n",
    "    \n",
    "    8, 9, 10, 11, 12, 13\n",
    "    \n",
    "    Para dos\n",
    "\n",
    "    8, 9, 10, 11, 12\n",
    "  \n",
    "#### En el '2019_07_22_0011'\n",
    "    \n",
    "    un maximo:\n",
    "\n",
    "    11, 12, 13, 14\n",
    "   \n",
    "\n",
    "    14, 16 (podría pasar por dos orbitas)\n",
    "\n",
    "    dos maximos: (tambien)\n",
    "    \n",
    "    11, 12, 13,\n",
    "\n",
    "#### En el '2019_07_22_0002'\n",
    "    \n",
    "    un maximo:\n",
    "    \n",
    "    10, 15, 12\n",
    "    \n",
    "    5, 8\n",
    "    \n",
    "    6, 11\n",
    "    \n",
    "    7, 9\n",
    "    \n",
    "    dos maximos\n",
    "    \n",
    "    9, 10, 11, ?6?\n",
    "    \n",
    "    1, 2\n",
    "    \n",
    "    5, 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruebo el Spectral Coclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1a005f1d0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_mat = NLD.compareCycles(np.array(every_single_cycle))\n",
    "dist_mat -= dist_mat.max()\n",
    "dist_mat *= -1\n",
    "from sklearn.cluster.bicluster import SpectralCoclustering\n",
    "from sklearn.metrics import consensus_score\n",
    "\n",
    "scores = []\n",
    "# for i in range(2, 15):\n",
    "i = 20\n",
    "if True:\n",
    "    model = SpectralCoclustering(n_clusters=i, random_state=0)\n",
    "    model.fit(dist_mat)\n",
    "    score = consensus_score(model.biclusters_,\n",
    "                            (model.rows_[model.rows_], model.columns_[model.columns_]))\n",
    "    # print(i, i*score)\n",
    "    scores.append(score)\n",
    "    # print(\"consensus score: {:.3f}\".format(score))\n",
    "\n",
    "    fit_data = dist_mat[np.argsort(model.row_labels_)]\n",
    "    fit_data = fit_data[:, np.argsort(model.column_labels_)]\n",
    "\n",
    "    # plt.matshow(fit_data, cmap=plt.cm.Blues)\n",
    "    plt.matshow(fit_data)\n",
    "    plt.colorbar()\n",
    "    plt.gca().set_aspect('auto')\n",
    "    plt.title(str(i))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\agus\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\pyplot.py:513: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for clust in model.biclusters_[0]:\n",
    "    fig, ax = plt.subplots()\n",
    "    from_file = np.unique(np.array(cycle_map)[clust])\n",
    "#     print(from_file)\n",
    "#     print('\\n')\n",
    "    for cycle in np.array(every_single_cycle)[clust]:\n",
    "        ax.plot(cycle)\n",
    "    ax.plot(np.mean(np.array(every_single_cycle)[clust], axis=0), color='k', linewidth=5)\n",
    "    fig.suptitle(\" \".join([os.path.splitext(os.path.basename(fn))[0] for fn in from_file]) + '\\n' + str(i))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Dobles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1c2ff04a8>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_dist_mat = NLD.compareCycles(np.array(every_single_cycle))\n",
    "double_dist_mat -= double_dist_mat.max()\n",
    "double_dist_mat *= -1\n",
    "\n",
    "double_scores = []\n",
    "for i in range(2, 15):\n",
    "# i = 20\n",
    "# if True:\n",
    "    double_model = SpectralCoclustering(n_clusters=i, random_state=0)\n",
    "    double_model.fit(double_dist_mat)\n",
    "    score = consensus_score(double_model.biclusters_,\n",
    "                            (double_model.rows_[double_model.rows_], double_model.columns_[double_model.columns_]))\n",
    "    # print(i, i*score)\n",
    "    scores.append(score)\n",
    "    # print(\"consensus score: {:.3f}\".format(score))\n",
    "\n",
    "    double_fit_data = double_dist_mat[np.argsort(double_model.row_labels_)]\n",
    "    double_fit_data = double_fit_data[:, np.argsort(double_model.column_labels_)]\n",
    "\n",
    "    # plt.matshow(fit_data, cmap=plt.cm.Blues)\n",
    "    plt.matshow(double_fit_data)\n",
    "    plt.colorbar()\n",
    "    plt.gca().set_aspect('auto')\n",
    "    plt.title(str(i))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(double_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 82 but corresponding boolean dimension is 89",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-71b41a6c2d2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclust\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdouble_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiclusters_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mfrom_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdouble_cycle_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclust\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#     print(from_file)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#     print('\\n')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 82 but corresponding boolean dimension is 89"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for clust in double_model.biclusters_[0]:\n",
    "    fig, ax = plt.subplots()\n",
    "    from_file = np.unique(np.array(double_cycle_map)[clust])\n",
    "#     print(from_file)\n",
    "#     print('\\n')\n",
    "    for cycle in np.array(every_double_cycle)[clust]:\n",
    "        ax.plot(cycle)\n",
    "    ax.plot(np.mean(np.array(every_double_cycle)[clust], axis=0), color='k', linewidth=5)\n",
    "    fig.suptitle(\" \".join([os.path.splitext(os.path.basename(fn))[0] for fn in from_file]) + '\\n' + str(i))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> clusters: 1, 4, 7, 9, 11, 16, 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "gc = [1, 4, 7, 9, 11, 16, 18]\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "cmap = plt.get_cmap('jet')\n",
    "cNorm = mpl.colors.Normalize(vmin=0, vmax=len(gc)- 1)\n",
    "scalarMap = mpl.cm.ScalarMappable(norm=cNorm, cmap=cmap)\n",
    "ls = np.linspace(0, 1, len(gc))\n",
    "i = 0\n",
    "for clust in gc:\n",
    "    mean_cycle = np.mean(np.array(every_single_cycle)[model.biclusters_[0][clust]], axis=0)\n",
    "    emb = NLD.getTraceEmbedding(mean_cycle, 100, 3)\n",
    "    NLD.plot3Dline(emb, fig_ax_pair=[fig, ax], label=str(clust), color=cmap(ls[i]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
