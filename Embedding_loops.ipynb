{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agus\\Dropbox\\Doctorado\\NeuroData\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyLeech.Utils.NLDUtils as NLD\n",
    "import PyLeech.Utils.AbfExtension as abfe\n",
    "\n",
    "import PyLeech.Utils.CrawlingDatabaseUtils as CDU\n",
    "import PyLeech.Utils.burstStorerLoader as bStorerLoader\n",
    "import PyLeech.Utils.burstUtils as burstUtils\n",
    "\n",
    "import numpy as np\n",
    "import scipy.signal as spsig\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matplotlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ac7c6f7fd3ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[1;34m'weight'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'normal'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         'size'   : 14}\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'figure.figsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'font'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matplotlib' is not defined"
     ]
    }
   ],
   "source": [
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 15)\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel Vm1 doesn't exists, check ch_info: \n",
      "{'id': 5, 'sampling_rate': 20000.0, 'dtype': 'int16', 'units': 'V', 'gain': 0.00030517578125, 'offset': 0.0, 'group_id': 0, 'index': 0}\n",
      "{'id': 6, 'sampling_rate': 20000.0, 'dtype': 'int16', 'units': 'V', 'gain': 0.00030517578125, 'offset': 0.0, 'group_id': 0, 'index': 1}\n",
      "Deleting block\n",
      "channel Vm1 doesn't exists, check ch_info: \n",
      "{'id': 5, 'sampling_rate': 15151.515151515154, 'dtype': 'int16', 'units': 'V', 'gain': 0.00030517578125, 'offset': 0.0, 'group_id': 0, 'index': 0}\n",
      "{'id': 6, 'sampling_rate': 15151.515151515154, 'dtype': 'int16', 'units': 'V', 'gain': 0.00030517578125, 'offset': 0.0, 'group_id': 0, 'index': 1}\n",
      "Deleting block\n",
      "I need to set attribute 'isDe3' before continuing\n",
      "I need to set attribute 'isDe3' before continuing\n"
     ]
    }
   ],
   "source": [
    "cdd = CDU.loadDataDict()\n",
    "cdb = CDU.loadCrawlingDatabase()\n",
    "file_list = []\n",
    "for files in list(cdd.keys()):\n",
    "    burst_obj = bStorerLoader.BurstStorerLoader(files, 'RegistrosDP_PP', mode='load')\n",
    "    try:\n",
    "        arr_dict, time_vector1, fs = abfe.getArraysFromAbfFiles(files, ['Vm1'])\n",
    "        file_list.append(files)\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_dt = 0.1\n",
    "kernel_sigma = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[350, 700]]\n",
      "I need to set attribute 'isDe3' before continuing\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "digitizeSpikeFreqs() got an unexpected keyword argument 'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bdc7781eda4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mkernel_sigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mnew_sfd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mburstUtils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremoveOutliers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mburst_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspike_freq_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mbinned_sfd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mburstUtils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdigitizeSpikeFreqs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_sfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinning_dt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_vector\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mcut_binned_freq_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mburstUtils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinned_spike_freq_dict_ToArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinned_sfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrawling_intervals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgood_neurons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: digitizeSpikeFreqs() got an unexpected keyword argument 'count'"
     ]
    }
   ],
   "source": [
    "for fn in [file_list[0]]:\n",
    "    arr_dict, time_vector, fs = abfe.getArraysFromAbfFiles(fn, ['Vm1'])\n",
    "    NS = arr_dict['Vm1']\n",
    "    del arr_dict\n",
    "\n",
    "\n",
    "    NS[(NS > -20) | (NS < -60)] = np.median(NS)\n",
    "    good_neurons = [neuron for neuron, neuron_dict in cdd[fn]['neurons'].items() if neuron_dict['neuron_is_good']]\n",
    "\n",
    "    crawling_intervals = cdd[fn]['crawling_intervals']\n",
    "    print(crawling_intervals)\n",
    "\n",
    "    burst_obj = bStorerLoader.BurstStorerLoader(fn, 'RegistrosDP_PP', mode='load')\n",
    "    \n",
    "    binning_dt = 0.1\n",
    "#     kernel_sigma = 5\n",
    "    kernel_sigma = 5\n",
    "    new_sfd = burstUtils.removeOutliers(burst_obj.spike_freq_dict, 5)\n",
    "    binned_sfd = burstUtils.digitizeSpikeFreqs(new_sfd, binning_dt, time_vector[-1], count=False)\n",
    "    cut_binned_freq_array = burstUtils.binned_spike_freq_dict_ToArray(binned_sfd, crawling_intervals, good_neurons)\n",
    "    \n",
    "    \n",
    "    kernel = NLD.generateGaussianKernel(sigma=kernel_sigma, time_range=20, dt_step=binning_dt)\n",
    "    smoothed_sfd = {}\n",
    "    for key, items in binned_sfd.items():\n",
    "        smoothed_sfd[key] = np.array([items[0], spsig.fftconvolve(items[1], kernel, mode='same')])\n",
    "    \n",
    "    step = int(binning_dt * fs)\n",
    "    neuron_idxs = []\n",
    "    for interval in crawling_intervals:\n",
    "        neuron_idxs.append(np.where((time_vector > interval[0]) & (time_vector < interval[1]))[0][::step])\n",
    "    neuron_idxs = np.hstack(neuron_idxs)\n",
    "\n",
    "    neuron_cut_time = time_vector[neuron_idxs]\n",
    "\n",
    "    kernel = NLD.generateGaussianKernel(sigma=kernel_sigma, time_range=30, dt_step=1 / fs)\n",
    "    conv_NS = spsig.fftconvolve(NS, kernel, mode='same')\n",
    "    cut_NS = conv_NS[neuron_idxs]\n",
    "\n",
    "#     fig, axes = burstUtils.plotFreq(smoothed_sfd, color_dict=burst_obj.color_dict,\n",
    "#                                     template_dict=burst_obj.template_dict, scatter_plot=False,\n",
    "#                                     optional_trace=[time_vector[::int(step / 4)], conv_NS[::int(step / 4)]],\n",
    "#                                     outlier_thres=None, ms=4)\n",
    "#     fig.suptitle(fn)\n",
    "\n",
    "#     NS_embedding = NLD.getDerivativeEmbedding(cut_NS, 0.1, 3)\n",
    "    \n",
    "    NS_embedding = NLD.getTraceEmbedding(cut_NS, int(5 / .1), 3)\n",
    "    jumps = np.where(np.diff(neuron_idxs) != np.diff(neuron_idxs)[0])[0]\n",
    "    if len(jumps) > 0:\n",
    "        NS_embedding[jumps] = np.nan\n",
    "        NS_embedding[jumps + 1] = np.nan\n",
    "\n",
    "#     scaler = StandardScaler()\n",
    "#     NS_embedding = scaler.fit_transform(NS_embedding)\n",
    "\n",
    "    fig, ax = NLD.plot3Dline(NS_embedding, color_idx=None)\n",
    "    fig.suptitle(fn)\n",
    "#     NS_embedding = NLD.getTraceEmbedding(cut_NS[:], int(1.2 / .1), 3)\n",
    "    rt1 = NLD.getCloseReturns(NS_embedding)\n",
    "\n",
    "#     reord_rt, fig1, ax1, \n",
    "    rt, fig1, ax1, fig2, ax2 = NLD.plotCloseReturns(rt1, get_counts=True, reorder=True, masked=False, thr=.1, return_reordered=True)\n",
    "    fig1.suptitle(fn)\n",
    "    fig2.suptitle(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in [file_list[0]]:\n",
    "    arr_dict, time_vector, fs = abfe.getArraysFromAbfFiles(fn, ['Vm1'])\n",
    "    NS = arr_dict['Vm1']\n",
    "    del arr_dict\n",
    "\n",
    "    NS[(NS > -20) | (NS < -60)] = np.median(NS)\n",
    "    good_neurons = [neuron for neuron, neuron_dict in cdd[fn]['neurons'].items() if neuron_dict['neuron_is_good']]\n",
    "\n",
    "    crawling_intervals = cdd[fn]['crawling_intervals']\n",
    "    print(crawling_intervals)\n",
    "\n",
    "    burst_obj = bStorerLoader.BurstStorerLoader(fn, 'RegistrosDP_PP', mode='load')\n",
    "    \n",
    "\n",
    "\n",
    "    new_sfd = burstUtils.removeOutliers(burst_obj.spike_freq_dict, 5)\n",
    "    binned_sfd = burstUtils.digitizeSpikeFreqs(new_sfd, binning_dt, time_vector[-1], count=False)\n",
    "    cut_binned_freq_array = burstUtils.binned_spike_freq_dict_ToArray(binned_sfd, crawling_intervals, good_neurons)\n",
    "    \n",
    "    \n",
    "    kernel = NLD.generateGaussianKernel(sigma=kernel_sigma, time_range=20, dt_step=binning_dt)\n",
    "    smoothed_sfd = {}\n",
    "    for key, items in binned_sfd.items():\n",
    "        smoothed_sfd[key] = np.array([items[0], spsig.fftconvolve(items[1], kernel, mode='same')])\n",
    "    \n",
    "    step = int(binning_dt * fs)\n",
    "    neuron_idxs = []\n",
    "    for interval in crawling_intervals:\n",
    "        neuron_idxs.append(np.where((time_vector > interval[0]) & (time_vector < interval[1]))[0][::step])\n",
    "    neuron_idxs = np.hstack(neuron_idxs)\n",
    "\n",
    "    neuron_cut_time = time_vector[neuron_idxs]\n",
    "\n",
    "    kernel = NLD.generateGaussianKernel(sigma=kernel_sigma, time_range=30, dt_step=1 / fs)\n",
    "    conv_NS = spsig.fftconvolve(NS, kernel, mode='same')\n",
    "    cut_NS = conv_NS[neuron_idxs]\n",
    "\n",
    "    \n",
    "#     NS_embedding = NLD.getDerivativeEmbedding(cut_NS, 0.1, 3)\n",
    "    NS_embedding = NLD.getTraceEmbedding(cut_NS, int(5 / .1), 3)\n",
    "    jumps = np.where(np.diff(neuron_idxs) != np.diff(neuron_idxs)[0])[0]\n",
    "    if len(jumps) > 0:\n",
    "        NS_embedding[jumps] = np.nan\n",
    "        NS_embedding[jumps + 1] = np.nan\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    NS_embedding = scaler.fit_transform(NS_embedding)\n",
    "    \n",
    "#     NLD.plot3Dline(NS_embedding)\n",
    "    rt1 = NLD.getCloseReturns(NS_embedding)\n",
    "\n",
    "\n",
    "    for pair in [[800, 1700], [1900, 2450]]:\n",
    "        fig, ax = NLD.plot3Dline(NS_embedding[pair[0]:pair[1]], color_idx=None)\n",
    "        ax.set_title(fn + '\\n' + str(pair[0]) + '-' + str(pair[1]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, ax = NLD.plot3Dline(NS_embedding[150:300], color_idx=None)\n",
    "    NLD.plot3Dline(NS_embedding[150+1400:300+1400], color_idx=None)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loops_dict = {\n",
    "    file_list[0]:\n",
    "        [\n",
    "            [180, 300+1050],\n",
    "            [520,750+550],\n",
    "            [850, 1050+350],\n",
    "            [1260, 1400+350]\n",
    "        ],\n",
    "    file_list[1]:\n",
    "        [\n",
    "            [70,150+290],\n",
    "            [350, 450+140],\n",
    "            \n",
    "        ],\n",
    "    file_list[2]:\n",
    "    [\n",
    "        [750, 900+335],\n",
    "        [750, 950+1250],\n",
    "        [750, 750 + 725],\n",
    "        [2220, 3000+100],\n",
    "        [1550, 1700+800],\n",
    "        [3280, 3400+280]\n",
    "    ],\n",
    "    file_list[3]:\n",
    "        [\n",
    "            [300, 800],\n",
    "            [1300, 1350+570],\n",
    "            [2200, 2500+225],\n",
    "            [2410, 2700+370],\n",
    "            [2450, 2500+550],\n",
    "            [170, 250+500],\n",
    "            \n",
    "    \n",
    "        ]      \n",
    "}\n",
    "loops_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in file_list:\n",
    "    arr_dict, time_vector, fs = abfe.getArraysFromAbfFiles(fn, ['Vm1'])\n",
    "    NS = arr_dict['Vm1']\n",
    "    del arr_dict\n",
    "\n",
    "\n",
    "    NS[(NS > -20) | (NS < -60)] = np.median(NS)\n",
    "    good_neurons = [neuron for neuron, neuron_dict in cdd[fn]['neurons'].items() if neuron_dict['neuron_is_good']]\n",
    "\n",
    "    crawling_intervals = cdd[fn]['crawling_intervals']\n",
    "    print(crawling_intervals)\n",
    "\n",
    "    burst_obj = bStorerLoader.BurstStorerLoader(fn, 'RegistrosDP_PP', mode='load')\n",
    "    \n",
    "\n",
    "\n",
    "    new_sfd = burstUtils.removeOutliers(burst_obj.spike_freq_dict, 5)\n",
    "    binned_sfd = burstUtils.digitizeSpikeFreqs(new_sfd, binning_dt, time_vector[-1], count=False)\n",
    "    cut_binned_freq_array = burstUtils.binned_spike_freq_dict_ToArray(binned_sfd, crawling_intervals, good_neurons)\n",
    "    \n",
    "    \n",
    "    kernel = NLD.generateGaussianKernel(sigma=kernel_sigma, time_range=20, dt_step=binning_dt)\n",
    "    smoothed_sfd = {}\n",
    "    for key, items in binned_sfd.items():\n",
    "        smoothed_sfd[key] = np.array([items[0], spsig.fftconvolve(items[1], kernel, mode='same')])\n",
    "\n",
    "    \n",
    "    \n",
    "    step = int(binning_dt * fs)\n",
    "    neuron_idxs = []\n",
    "    for interval in crawling_intervals:\n",
    "        neuron_idxs.append(np.where((time_vector > interval[0]) & (time_vector < interval[1]))[0][::step])\n",
    "    neuron_idxs = np.hstack(neuron_idxs)\n",
    "\n",
    "    neuron_cut_time = time_vector[neuron_idxs]\n",
    "\n",
    "    kernel = NLD.generateGaussianKernel(sigma=kernel_sigma, time_range=30, dt_step=1 / fs)\n",
    "    conv_NS = spsig.fftconvolve(NS, kernel, mode='same')\n",
    "    cut_NS = conv_NS[neuron_idxs]\n",
    "\n",
    "    \n",
    "    NS_embedding = NLD.getDerivativeEmbedding(cut_NS, 0.1, 3)\n",
    "    jumps = np.where(np.diff(neuron_idxs) != np.diff(neuron_idxs)[0])[0]\n",
    "    if len(jumps) > 0:\n",
    "        NS_embedding[jumps] = np.nan\n",
    "        NS_embedding[jumps + 1] = np.nan\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    NS_embedding = scaler.fit_transform(NS_embedding)\n",
    "    \n",
    "#     NLD.plot3Dline(NS_embedding)\n",
    "    rt1 = NLD.getCloseReturns(NS_embedding)\n",
    "\n",
    "\n",
    "    for pair in loops_dict[fn]:\n",
    "        fig, ax = NLD.plot3Dline(NS_embedding[pair[0]:pair[1]])\n",
    "        ax.set_title(fn + '\\n' + str(pair[0]) + '-' + str(pair[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in file_list:\n",
    "    arr_dict, time_vector, fs = abfe.getArraysFromAbfFiles(fn, ['Vm1'])\n",
    "    NS = arr_dict['Vm1']\n",
    "    del arr_dict\n",
    "\n",
    "\n",
    "    NS[(NS > -20) | (NS < -60)] = np.median(NS)\n",
    "    good_neurons = [neuron for neuron, neuron_dict in cdd[fn]['neurons'].items() if neuron_dict['neuron_is_good']]\n",
    "\n",
    "    crawling_intervals = cdd[fn]['crawling_intervals']\n",
    "    print(crawling_intervals)\n",
    "\n",
    "    burst_obj = bStorerLoader.BurstStorerLoader(fn, 'RegistrosDP_PP', mode='load')\n",
    "    \n",
    "    binning_dt = 0.1\n",
    "    kernel_sigma = 1\n",
    "    \n",
    "    new_sfd = burstUtils.removeOutliers(burst_obj.spike_freq_dict, 5)\n",
    "    binned_sfd = burstUtils.digitizeSpikeFreqs(new_sfd, binning_dt, time_vector[-1], count=False)\n",
    "    cut_binned_freq_array = burstUtils.binned_spike_freq_dict_ToArray(binned_sfd, crawling_intervals, good_neurons)\n",
    "    \n",
    "    \n",
    "    kernel = NLD.generateGaussianKernel(sigma=kernel_sigma, time_range=20, dt_step=binning_dt)\n",
    "    smoothed_sfd = {}\n",
    "    for key, items in binned_sfd.items():\n",
    "        smoothed_sfd[key] = np.array([items[0], spsig.fftconvolve(items[1], kernel, mode='same')])\n",
    "    \n",
    "    step = int(binning_dt * fs)\n",
    "    neuron_idxs = []\n",
    "    for interval in crawling_intervals:\n",
    "        neuron_idxs.append(np.where((time_vector > interval[0]) & (time_vector < interval[1]))[0][::step])\n",
    "    neuron_idxs = np.hstack(neuron_idxs)\n",
    "\n",
    "    neuron_cut_time = time_vector[neuron_idxs]\n",
    "\n",
    "    kernel = NLD.generateGaussianKernel(sigma=kernel_sigma, time_range=30, dt_step=1 / fs)\n",
    "    conv_NS = spsig.fftconvolve(NS, kernel, mode='same')\n",
    "    cut_NS = conv_NS[neuron_idxs]\n",
    "\n",
    "    fig, axes = burstUtils.plotFreq(smoothed_sfd, color_dict=burst_obj.color_dict,\n",
    "                                    template_dict=burst_obj.template_dict, scatter_plot=False,\n",
    "                                    optional_trace=[time_vector[::int(step / 4)], conv_NS[::int(step / 4)]],\n",
    "                                    outlier_thres=None, ms=4)\n",
    "    fig.suptitle(fn)\n",
    "    for key, items in smoothed_sfd.items():\n",
    "        if cdd[fn]['neurons'][key]['neuron_is_good']:\n",
    "            embedding = NLD.getDerivativeEmbedding(items[1], 0.1, 3)\n",
    "            jumps = np.where(np.diff(neuron_idxs) != np.diff(neuron_idxs)[0])[0]\n",
    "            if len(jumps) > 0:\n",
    "                NS_embedding[jumps] = np.nan\n",
    "                NS_embedding[jumps + 1] = np.nan\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            embedding = scaler.fit_transform(embedding)\n",
    "\n",
    "            fig, ax = NLD.plot3Dline(NS_embedding)\n",
    "            fig.suptitle(fn + '\\n' + str(key))\n",
    "    #     NS_embedding = NLD.getTraceEmbedding(cut_NS[:], int(1.2 / .1), 3)\n",
    "            rt1 = NLD.getCloseReturns(NS_embedding)\n",
    "\n",
    "    #     reord_rt, fig1, ax1, \n",
    "            rt, fig1, ax1, fig2, ax2 = NLD.plotCloseReturns(rt1, get_counts=True, reorder=True, masked=False, thr=.1, return_reordered=True)\n",
    "    #     fig1.suptitle(fn)\n",
    "            fig2.suptitle(fn + '\\n' + str(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
